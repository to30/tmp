[COMMON]

# Username for OpenStack (string value)
#OS_USERNAME = 'admin'

# Password for OpenStack (string value)
#OS_PASSWORD = 'admin'

# Tenant name for OpenStack (string value)
#OS_TENANT_NAME = 'admin'

# URL for OpenStack (string value)
#OS_AUTH_URL = 'http://127.0.0.1:5000/v2.0'

# OpenStack auth version for Swift (string value)
#SWIFT_AUTH_VERSION = 2

#  Project name for OpenStack (string value)
#OS_PROJECT_NAME = 'admin'

# The BYPASS_URL value to pass to the cli (string value)
#BYPASS_URL = <None>

# Cluster creation timeout (in minutes); minimal value is 1 (integer value)
#CLUSTER_CREATION_TIMEOUT = 10

# A keypair id to use during cluster launch.
# If the id is left blank, an id will be generated. '
# If the id names an existing keypair, that keypair will
# be used. If the named keypair does not exist, it will be
# created and deleted after the test (string value)
#USER_KEYPAIR_ID = <None>

# Length of time (in minutes) to wait after cluster is active
# before running jobs (integer value)
#DELAY_AFTER_ACTIVE = 2

# Pool name for floating IPs. If Sahara uses Nova
# management network and auto assignment of IPs was
# enabled then you should leave default value of this
# parameter. If auto assignment was not enabled, then you
# should specify value (floating IP pool name) of this
# parameter. If Sahara uses Neutron management network,
# then you should always specify value (floating IP pool
# name) of this parameter (string value)
#FLOATING_IP_POOL = <None>

# If Sahara uses Nova management network, then you
# should leave default value of this flag. If Sahara
# uses Neutron management network, then you should set
# this flag to True and specify values of the following
# parameters: FLOATING_IP_POOL and INTERNAL_NEUTRON_NETWORK
# (boolean value)
#NEUTRON_ENABLED = False

# Name for internal Neutron network (string value)
#INTERNAL_NEUTRON_NETWORK = 'private'

# Job launch timeout (in minutes); minimal value is 1
# (integer value)
#JOB_LAUNCH_TIMEOUT = 10

# Store job binary data in the sahara internal database.
# If this option is set to False, job binary data will be stored in swift
# (boolean value)
#INTERNAL_JOB_BINARIES = True

# Name for cluster (string value)
#CLUSTER_NAME = 'test'

[VANILLA]

# The id of an existing active cluster
# to use for the test instead of building one.
# Cluster teardown will be skipped. This has priority
# over EXISTING_CLUSTER_NAME (string value)
#EXISTING_CLUSTER_ID = <None>

# The name of an existing active cluster
# to use for the test instead of building one.
# Cluster teardown will be skipped. This is superseded
# by EXISTING_CLUSTER_ID (string value)
#EXISTING_CLUSTER_NAME = <None>

# ID for image which is used for cluster creation.
# You can also specify image name or tag of image instead
# of image ID. If you do not specify image related
# parameters then the image for cluster creation will be
# chosen by tag "sahara_i_tests" (string value)
#IMAGE_ID = <None>

# Name for image which is used for cluster creation.
# You can also specify image ID or tag of image instead of
# image name. If you do not specify image related
# parameters then the image for cluster creation will be
# chosen by tag "sahara_i_tests" (string value)
#IMAGE_NAME = <None>

# Tag for image which is used for cluster creation.
# You can also specify image ID or image name instead of
# the image tag. If you do not specify image related
# parameters, then the image for cluster creation will be
# chosen by the tag "sahara_i_tests" (string value)
#IMAGE_TAG = <None>

# Username used to log into a cluster node via SSH (string value)
#SSH_USERNAME = <None>

# Skip tearing down the cluster. If an existing
# cluster is used it will never be torn down by the test (boolean value)
#SKIP_CLUSTER_TEARDOWN = False

# Version of Hadoop (string value)
#HADOOP_VERSION = '1.2.1'

# Name of plugin (string value)
#PLUGIN_NAME = 'vanilla'

# If this option is set True no tests for this plugin will be run
# (boolean value)
#SKIP_ALL_TESTS_FOR_PLUGIN = False

# If this option is set True no Java EDP job will be submitted
# (boolean value)
#SKIP_JAVA_EDP_TEST = False

# If this option is set True no MapReduce EDP job will be submitted
# (boolean value)
#SKIP_MAPREDUCE_EDP_TEST = False

# If this option is set True no Streaming MapReduce EDP job
# will be submitted  (boolean value)
#SKIP_MAPREDUCE_STREAMING_EDP_TEST = False

# If this option is set True no Pig EDP job will be submitted
# (boolean value)
#SKIP_PIG_EDP_TEST = False

[VANILLA2]

# The id of an existing active cluster
# to use for the test instead of building one.
# Cluster teardown will be skipped. This has priority
# over EXISTING_CLUSTER_NAME (string value)
#EXISTING_CLUSTER_ID = <None>

# The name of an existing active cluster
# to use for the test instead of building one.
# Cluster teardown will be skipped. This is superseded
# by EXISTING_CLUSTER_ID (string value)
#EXISTING_CLUSTER_NAME = <None>

# ID for image which is used for cluster creation.
# You can also specify image name or tag of image instead
# of image ID. If you do not specify image related
# parameters then the image for cluster creation will be
# chosen by tag "sahara_i_tests" (string value)
#IMAGE_ID = <None>

# Name for image which is used for cluster creation.
# You can also specify image ID or tag of image instead of
# image name. If you do not specify image related
# parameters then the image for cluster creation will be
# chosen by tag "sahara_i_tests" (string value)
#IMAGE_NAME = <None>

# Tag for image which is used for cluster creation.
# You can also specify image ID or image name instead of
# the image tag. If you do not specify image related
# parameters, then the image for cluster creation will be
# chosen by the tag "sahara_i_tests" (string value)
#IMAGE_TAG = <None>

# Username used to log into a cluster node via SSH (string value)
#SSH_USERNAME = <None>

# Skip tearing down the cluster. If an existing
# cluster is used it will never be torn down by the test (boolean value)
#SKIP_CLUSTER_TEARDOWN = False

# Version of Hadoop (string value)
#HADOOP_VERSION = '2.3.0'

# Name of plugin (string value)
#PLUGIN_NAME = 'vanilla'

# If this option is set True, no tests for this plugin will be run
# (boolean value)
#SKIP_ALL_TESTS_FOR_PLUGIN = True

# If this option is set True no Java EDP job will be submitted
# (boolean value)
#SKIP_JAVA_EDP_TEST = False

# If this option is set True no MapReduce EDP job will be submitted
# (boolean value)
#SKIP_MAPREDUCE_EDP_TEST = False

# If this option is set True no Streaming MapReduce EDP job
# will be submitted  (boolean value)
#SKIP_MAPREDUCE_STREAMING_EDP_TEST = False

# If this option is set True no Pig EDP job will be submitted
# (boolean value)
#SKIP_PIG_EDP_TEST = False

[HDP]

# The id of an existing active cluster
# to use for the test instead of building one.
# Cluster teardown will be skipped. This has priority
# over EXISTING_CLUSTER_NAME (string value)
#EXISTING_CLUSTER_ID = <None>

# The name of an existing active cluster
# to use for the test instead of building one.
# Cluster teardown will be skipped. This is superseded
# by EXISTING_CLUSTER_ID (string value)
#EXISTING_CLUSTER_NAME = <None>

# ID for image which is used for cluster creation.
# You can also specify image name or tag of image instead
# of image ID. If you do not specify image related
# parameters then the image for cluster creation will be
# chosen by tag "sahara_i_tests" (string value)
#IMAGE_ID = <None>

# Name for image which is used for cluster creation.
# You can also specify image ID or tag of image instead of
# image name. If you do not specify image related
# parameters then the image for cluster creation will be
# chosen by tag "sahara_i_tests" (string value)
#IMAGE_NAME = <None>

# Tag for image which is used for cluster creation.
# You can also specify image ID or image name instead of
# the image tag. If you do not specify image related
# parameters, then the image for cluster creation will be
# chosen by the tag "sahara_i_tests" (string value)
#IMAGE_TAG = <None>

# Username used to log into a cluster node via SSH (string value)
#SSH_USERNAME = <None>

# Skip tearing down the cluster. If an existing
# cluster is used it will never be torn down by the test (boolean value)
#SKIP_CLUSTER_TEARDOWN = False

# Version of Hadoop (string value)
#HADOOP_VERSION = '1.3.2'

# Name of plugin (string value)
#PLUGIN_NAME = 'hdp'

# If this option is set True, no tests for this plugin will be run
# (boolean value)
#SKIP_ALL_TESTS_FOR_PLUGIN = True

# If this option is set True no Java EDP job will be submitted
# (boolean value)
#SKIP_JAVA_EDP_TEST = False

# If this option is set True no MapReduce EDP job will be submitted
# (boolean value)
#SKIP_MAPREDUCE_EDP_TEST = False

# If this option is set True no Streaming MapReduce EDP job
# will be submitted  (boolean value)
#SKIP_MAPREDUCE_STREAMING_EDP_TEST = False

# If this option is set True no Pig EDP job will be submitted
# (boolean value)
#SKIP_PIG_EDP_TEST = False
